{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "****\n",
      "***\n",
      "**\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for i in range(n):\n",
    "    print(\"*\"*n)\n",
    "    n -=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*\n",
      "**\n",
      "***\n",
      "****\n",
      "*****\n"
     ]
    }
   ],
   "source": [
    "# i = 0\n",
    "n = 6\n",
    "for i in range(n):\n",
    "    print(\"*\"*i)\n",
    "    # n -=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "\n",
      "*\n",
      "**\n",
      "***\n",
      "****\n",
      "\n",
      "*\n",
      "**\n",
      "***\n",
      "\n",
      "*\n",
      "**\n",
      "\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "for i in range(n):\n",
    "    print(\"*\"*n)\n",
    "    n -=1\n",
    "    for j in range(n):\n",
    "     print(\"*\"*j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     \n",
      "    * \n",
      "   * * \n",
      "  * * * \n",
      " * * * * \n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "m = 0\n",
    "for i in range(n):\n",
    "    m=i\n",
    "    for j in range(n):\n",
    "        if m<n:\n",
    "            print(\"\", end=\" \")\n",
    "        \n",
    "        else:\n",
    "            print(\"*\", end=\" \")\n",
    "        \n",
    "        m+=1\n",
    "\n",
    "    print(end=\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "m = 0\n",
    "for i in range(n):\n",
    "    print(\"*\"*n)\n",
    "    n =1\n",
    "    for j in range(n):\n",
    "        if m>n:\n",
    "            print(\"*\", end=\"\")\n",
    "        \n",
    "        else:\n",
    "            print(\"*\", end=\"\")\n",
    "        \n",
    "        m-=1\n",
    "\n",
    "    print(end=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "# Create output directory for generated images\n",
    "os.makedirs(\"generated_images\", exist_ok=True)\n",
    "print(\"‚úÖ Created output directory for generated images.\")\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "print(\"‚úÖ Initialized Binary Cross Entropy Loss.\")\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "print(\"‚úÖ Initialized optimizers.\")\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 1\n",
    "z_dim = 100  # Latent space dimension\n",
    "print(f\"‚úÖ Training will run for {num_epochs} epochs with latent dimension {z_dim}.\")\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nüöÄ Starting Epoch {epoch+1}/{num_epochs}...\")\n",
    "    total_loss_D, total_loss_G = 0, 0  # Track losses\n",
    "\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        batch_size = real_images.size(0)\n",
    "        real_images = real_images.cuda()\n",
    "        \n",
    "        # Print batch processing info\n",
    "        print(f\"üñºÔ∏è Processing batch {i+1}/{len(dataloader)}, Batch size: {batch_size}\")\n",
    "\n",
    "        # Train Discriminator\n",
    "        real_labels = torch.ones(batch_size, 1).cuda()\n",
    "        fake_labels = torch.zeros(batch_size, 1).cuda()\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "        outputs = discriminator(real_images).view(-1, 1)\n",
    "        loss_real = criterion(outputs, real_labels)\n",
    "        print(f\"üîµ Discriminator loss on real images: {loss_real.item():.4f}\")\n",
    "\n",
    "        z = torch.randn(batch_size, z_dim, 1, 1).cuda()\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images.detach()).view(-1, 1)\n",
    "        loss_fake = criterion(outputs, fake_labels)\n",
    "        print(f\"üî¥ Discriminator loss on fake images: {loss_fake.item():.4f}\")\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "        total_loss_D += loss_D.item()\n",
    "\n",
    "        # Train Generator\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images).view(-1, 1)\n",
    "        loss_G = criterion(outputs, real_labels)\n",
    "\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        total_loss_G += loss_G.item()\n",
    "\n",
    "        # Print intermediate loss values every 50 batches\n",
    "        if i % 50 == 0:\n",
    "            print(f\"[Epoch {epoch+1}/{num_epochs}] Step {i}/{len(dataloader)} | D Loss: {loss_D.item():.4f} | G Loss: {loss_G.item():.4f}\")\n",
    "\n",
    "    # Print epoch summary\n",
    "    avg_loss_D = total_loss_D / len(dataloader)\n",
    "    avg_loss_G = total_loss_G / len(dataloader)\n",
    "    print(f\"\\n‚úÖ Epoch [{epoch+1}/{num_epochs}] Completed!\")\n",
    "    print(f\"üìâ Average D Loss: {avg_loss_D:.4f} | üé® Average G Loss: {avg_loss_G:.4f}\")\n",
    "\n",
    "    # Save generated images every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            print(\"üé® Generating sample images...\")\n",
    "            z = torch.randn(16, z_dim, 1, 1).cuda()\n",
    "            fake_images = generator(z).detach().cpu()\n",
    "            fake_images = (fake_images + 1) / 2  # Rescale to [0,1]\n",
    "\n",
    "            grid_img = vutils.make_grid(fake_images, nrow=4)\n",
    "            save_path = f\"generated_images/epoch_{epoch+1}.png\"\n",
    "            vutils.save_image(grid_img, save_path)\n",
    "\n",
    "            print(f\"üñºÔ∏è Saved sample images: {save_path}\")\n",
    "\n",
    "print(\"\\nüéâ Training complete! Check 'generated_images' folder for results.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
