{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iris Classification: Logistic Regression ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"--- Iris Classification: Logistic Regression ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Loading Iris dataset...\n",
      " Dataset loaded.\n",
      " Features (X) shape: (150, 4), Target (y) shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Loading Iris dataset\n",
    "print(\"\\nStep 1: Loading Iris dataset...\")\n",
    "# The Iris dataset contains measurements (sepal length/width, petal length/width)\n",
    "# for 3 species of Iris flowers (Setosa, Versicolor, Virginica).\n",
    "# Goal: Predict the species based on measurements.\n",
    "iris = load_iris()\n",
    "X = iris.data  # Features (the measurements)\n",
    "y = iris.target  # Target variable (the species labels: 0, 1, 2)\n",
    "print(\" Dataset loaded.\")\n",
    "print(f\" Features (X) shape: {X.shape}, Target (y) shape: {y.shape}\") # Shows (samples, features) and (samples,)\n",
    "# print(\"X ==\",X)\n",
    "# print(\"y ==\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Splitting data into Training and Testing sets...\n",
      " Data successfully split.\n",
      " Training set size: 105 samples\n",
      " Testing set size: 45 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Splitting data into Training and Testing sets\n",
    "print(\"\\nStep 2: Splitting data into Training and Testing sets...\")\n",
    "# We split the data to train the model on one subset (training set)\n",
    "# and evaluate its performance on a separate, unseen subset (testing set).\n",
    "# This helps assess how well the model generalizes to new data.\n",
    "# test_size=0.3 means 30% of data is for testing, 70% for training.\n",
    "# random_state ensures the split is the same every time we run the code (reproducibility).\n",
    "# stratify=y ensures the proportion of each class (species) is the same in both train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "print(\" Data successfully split.\")\n",
    "print(f\" Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\" Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "###################################################################################################################################\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Initializing and Training the Logistic Regression model...\n",
      " Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initializing and Training the Logistic Regression model\n",
    "print(\"\\nStep 3: Initializing and Training the Logistic Regression model...\")\n",
    "# Initialize the Logistic Regression classifier. max_iter is increased to help convergence.\n",
    "model = LogisticRegression(max_iter=9999999999999999999999999999999)\n",
    "# Train the model using the training data (X_train, y_train).\n",
    "# The .fit() method learns the relationship between features and the target variable.\n",
    "model.fit(X_train, y_train)\n",
    "print(\" Model training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Making predictions on the test set...\n",
      " Predictions made.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Making predictions on the test set\n",
    "print(\"\\nStep 4: Making predictions on the test set...\")\n",
    "# Use the trained model to predict the species for the unseen test data (X_test).\n",
    "y_pred = model.predict(X_test)\n",
    "print(\" Predictions made.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Evaluating the model...\n",
      " Model Accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluating the model\n",
    "print(\"\\nStep 5: Evaluating the model...\")\n",
    "# Compare the model's predictions (y_pred) with the actual species (y_test).\n",
    "# Accuracy is the proportion of correct predictions.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\" Model Accuracy: {accuracy:.4f}\") # Format to 4 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions vs Actual Labels:\n",
      " Sample 1: Predicted='virginica', Actual='virginica'\n",
      " Sample 2: Predicted='versicolor', Actual='versicolor'\n",
      " Sample 3: Predicted='versicolor', Actual='virginica'\n",
      " Sample 4: Predicted='versicolor', Actual='versicolor'\n",
      " Sample 5: Predicted='virginica', Actual='virginica'\n"
     ]
    }
   ],
   "source": [
    "# Optional: Display a few predictions alongside the actual values\n",
    "print(\"\\nSample Predictions vs Actual Labels:\")\n",
    "for i in range(min(5, len(y_test))): # Show up to 5 samples\n",
    "    predicted_species = iris.target_names[y_pred[i]]\n",
    "  \n",
    "    actual_species = iris.target_names[y_test[i]]\n",
    "    print(f\" Sample {i+1}: Predicted='{predicted_species}', Actual='{actual_species}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Diabetes Progression Prediction: Linear Regression ---\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"\\n\\n--- Diabetes Progression Prediction: Linear Regression ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Loading Diabetes dataset...\n",
      " Dataset loaded.\n",
      " Features (X) shape: (442, 10), Target (y) shape: (442,)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Loading Diabetes dataset\n",
    "print(\"\\nStep 1: Loading Diabetes dataset...\")\n",
    "# The Diabetes dataset contains patient baseline physiological measurements\n",
    "# (age, sex, bmi, blood pressure, etc.) and a quantitative measure of\n",
    "# disease progression one year later.\n",
    "# Goal: Predict the disease progression score based on the baseline measurements.\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data  # Features (baseline measurements)\n",
    "y = diabetes.target # Target variable (disease progression score)\n",
    "print(\" Dataset loaded.\")\n",
    "print(f\" Features (X) shape: {X.shape}, Target (y) shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 2: Splitting data into Training and Testing sets...\n",
      " Data successfully split.\n",
      " Training set size: 309 samples\n",
      " Testing set size: 133 samples\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Splitting data into Training and Testing sets\n",
    "print(\"\\nStep 2: Splitting data into Training and Testing sets...\")\n",
    "# Similar to classification, we split data for training and unbiased evaluation.\n",
    "# For regression, stratify is typically not used unless target has specific bins.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\" Data successfully split.\")\n",
    "print(f\" Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\" Testing set size: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Initializing and Training the Linear Regression model...\n",
      " Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Initializing and Training the Linear Regression model\n",
    "print(\"\\nStep 3: Initializing and Training the Linear Regression model...\")\n",
    "# Initialize the Linear Regression model.\n",
    "model = LinearRegression()\n",
    "# Train the model using the training data.\n",
    "# For linear regression, .fit() finds the optimal coefficients (slope and intercept)\n",
    "# for the linear equation that best fits the training data.\n",
    "model.fit(X_train, y_train)\n",
    "print(\" Model training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 4: Making predictions on the test set...\n",
      " Predictions made.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Making predictions on the test set\n",
    "print(\"\\nStep 4: Making predictions on the test set...\")\n",
    "# Use the trained model to predict the disease progression score for the unseen test data.\n",
    "y_pred = model.predict(X_test)\n",
    "print(\" Predictions made.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 5: Evaluating the model...\n",
      " Mean Squared Error (MSE): 2821.75\n",
      " R-squared (R2): 0.4773\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluating the model\n",
    "print(\"\\nStep 5: Evaluating the model...\")\n",
    "# Compare the model's predictions (y_pred) with the actual scores (y_test).\n",
    "# Mean Squared Error (MSE): Average of the squared differences between prediction and actual. Lower is better. Sensitive to outliers.\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "# R-squared (R2): Proportion of variance in the target variable explained by the model. Ranges from 0 to 1 (ideally). Higher is better.\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\" Mean Squared Error (MSE): {mse:.2f}\") # Format to 2 decimal places\n",
    "print(f\" R-squared (R2): {r2:.4f}\") # Format to 4 decimal places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Predictions vs Actual Scores:\n",
      " Sample 1: Predicted=138.47, Actual=219.00\n",
      " Sample 2: Predicted=181.10, Actual=70.00\n",
      " Sample 3: Predicted=125.34, Actual=202.00\n",
      " Sample 4: Predicted=292.76, Actual=230.00\n",
      " Sample 5: Predicted=123.88, Actual=111.00\n"
     ]
    }
   ],
   "source": [
    "# Optional: Display a few predictions alongside the actual values\n",
    "print(\"\\nSample Predictions vs Actual Scores:\")\n",
    "for i in range(min(5, len(y_test))): # Show up to 5 samples\n",
    "    print(f\" Sample {i+1}: Predicted={y_pred[i]:.2f}, Actual={y_test[i]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
